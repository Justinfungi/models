#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
debug_model.py - æ¨¡å‹è°ƒè¯•å·¥å…·
æä¾›è¯¦ç»†çš„æ¨¡å‹è¯Šæ–­å’Œä¿®å¤å»ºè®®
"""

import os
import sys
import numpy as np
import pandas as pd
import torch
import yaml
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
import logging
import traceback

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class ModelDebugger:
    """æ¨¡å‹è°ƒè¯•å™¨"""

    def __init__(self):
        self.models_dir = Path(__file__).parent
        self.model_names = [
            '20241113-æ‹›å•†è¯åˆ¸-AIç³»åˆ—ç ”ç©¶ä¹‹å››ï¼šæ··åˆé¢‘ç‡é‡ä»·å› å­æ¨¡å‹åˆæ¢',
            'BayesianCNN',
            'CS_tree_XGBoost_CS_Tree_Model',
            'HRM',
            'mamba',
            'TKAN',
            'wanglang_20250916_Conv_Trans',
            'wanglang_20250916_ConvM_Lstm'
        ]
        self.sample_data_path = self.models_dir / "sample_data"

    def load_sample_data(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """åŠ è½½ç¤ºä¾‹æ•°æ®"""
        try:
            features_path = self.sample_data_path / "features.csv"
            labels_path = self.sample_data_path / "labels.npy"

            if not features_path.exists() or not labels_path.exists():
                print("âŒ ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ: python create_sample_data.py")
                return None, None

            features = pd.read_csv(features_path)
            labels = np.load(labels_path)

            print(f"âœ… åŠ è½½ç¤ºä¾‹æ•°æ®: {len(features)} æ ·æœ¬, {len(features.columns)} ç‰¹å¾")
            return features, labels

        except Exception as e:
            print(f"âŒ åŠ è½½ç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")
            return None, None

    def diagnose_model_config(self, model_name: str) -> Dict[str, Any]:
        """è¯Šæ–­æ¨¡å‹é…ç½®"""
        result = {
            'config_valid': False,
            'num_classes_correct': False,
            'output_dim_correct': False,
            'loss_function_correct': False,
            'issues': [],
            'suggestions': []
        }

        model_path = self.models_dir / model_name
        config_path = model_path / "config.yaml"

        if not config_path.exists():
            result['issues'].append("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            result['suggestions'].append("åˆ›å»ºconfig.yamlæ–‡ä»¶")
            return result

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)

            result['config_valid'] = True

            # æ£€æŸ¥num_classes
            num_classes = self._extract_num_classes(config)
            if num_classes == 3:
                result['num_classes_correct'] = True
            else:
                result['issues'].append(f"num_classes = {num_classes}, åº”ä¸º3")
                result['suggestions'].append("è®¾ç½® num_classes: 3")

            # æ£€æŸ¥è¾“å‡ºç»´åº¦
            output_dim = self._extract_output_dim(config)
            if output_dim in [3, None]:  # Noneè¡¨ç¤ºè‡ªåŠ¨æ¨æ–­
                result['output_dim_correct'] = True
            else:
                result['issues'].append(f"output_dim = {output_dim}, åº”ä¸º3")
                result['suggestions'].append("è®¾ç½® output_dim: 3")

            # æ£€æŸ¥æŸå¤±å‡½æ•°
            loss_function = self._extract_loss_function(config)
            if loss_function in ['categorical_crossentropy', 'cross_entropy', None]:
                result['loss_function_correct'] = True
            elif loss_function == 'binary_crossentropy':
                result['issues'].append("ä½¿ç”¨äºŒåˆ†ç±»æŸå¤±å‡½æ•°ï¼Œåº”æ”¹ä¸ºå¤šåˆ†ç±»")
                result['suggestions'].append("æ”¹ä¸º categorical_crossentropy æˆ– cross_entropy")

        except Exception as e:
            result['issues'].append(f"é…ç½®è§£æé”™è¯¯: {e}")
            result['suggestions'].append("æ£€æŸ¥YAMLæ ¼å¼")

        return result

    def _extract_num_classes(self, config: Dict[str, Any]) -> Optional[int]:
        """ä»é…ç½®ä¸­æå–num_classes"""
        locations = [
            ('model', 'num_classes'),
            ('task', 'num_classes'),
            ('architecture', 'num_classes'),
            ('architecture', 'classifier', 'num_classes')
        ]

        for location in locations:
            value = config
            try:
                for key in location:
                    value = value[key]
                return value
            except (KeyError, TypeError):
                continue
        return None

    def _extract_output_dim(self, config: Dict[str, Any]) -> Optional[int]:
        """ä»é…ç½®ä¸­æå–output_dim"""
        locations = [
            ('architecture', 'output_dim'),
            ('model', 'output_dim'),
            ('architecture', 'network', 'output_dim')
        ]

        for location in locations:
            value = config
            try:
                for key in location:
                    value = value[key]
                return value
            except (KeyError, TypeError):
                continue
        return None

    def _extract_loss_function(self, config: Dict[str, Any]) -> Optional[str]:
        """ä»é…ç½®ä¸­æå–æŸå¤±å‡½æ•°"""
        locations = [
            ('training', 'loss', 'type'),
            ('training', 'loss_function'),
            ('loss', 'type'),
            ('loss_function',)
        ]

        for location in locations:
            value = config
            try:
                for key in location:
                    value = value[key]
                return value
            except (KeyError, TypeError):
                continue
        return None

    def diagnose_model_code(self, model_name: str) -> Dict[str, Any]:
        """è¯Šæ–­æ¨¡å‹ä»£ç """
        result = {
            'code_exists': False,
            'imports_work': False,
            'class_structure': False,
            'forward_method': False,
            'training_method': False,
            'issues': [],
            'suggestions': []
        }

        model_path = self.models_dir / model_name

        # æŸ¥æ‰¾Pythonæ–‡ä»¶
        python_files = list(model_path.glob('*.py'))
        if not python_files:
            result['issues'].append("æ²¡æœ‰æ‰¾åˆ°Pythonæ–‡ä»¶")
            result['suggestions'].append("åˆ›å»ºæ¨¡å‹å®ç°æ–‡ä»¶")
            return result

        result['code_exists'] = True

        # æ£€æŸ¥æ¯ä¸ªPythonæ–‡ä»¶
        for py_file in python_files:
            if py_file.name.startswith('test_') or py_file.name.startswith('debug_'):
                continue

            try:
                # æ·»åŠ åˆ°Pythonè·¯å¾„
                if str(model_path) not in sys.path:
                    sys.path.insert(0, str(model_path))

                # åŠ¨æ€å¯¼å…¥
                module_name = py_file.stem
                import importlib.util
                spec = importlib.util.spec_from_file_location(module_name, py_file)

                if spec and spec.loader:
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)
                    result['imports_work'] = True

                    # æ£€æŸ¥ç±»ç»“æ„
                    model_classes = []
                    for attr_name in dir(module):
                        attr = getattr(module, attr_name)
                        if hasattr(attr, '__bases__') and hasattr(attr, '__dict__'):
                            # æ‰¾åˆ°æ¨¡å‹ç±»
                            if 'Model' in attr_name and hasattr(attr, 'forward'):
                                model_classes.append(attr_name)
                                result['class_structure'] = True

                                # æ£€æŸ¥forwardæ–¹æ³•
                                if hasattr(attr, 'forward'):
                                    result['forward_method'] = True

                                # æ£€æŸ¥è®­ç»ƒç›¸å…³æ–¹æ³•
                                training_methods = ['fit', 'train_epoch', 'train']
                                if any(hasattr(attr, method) for method in training_methods):
                                    result['training_method'] = True

                    if not model_classes:
                        result['issues'].append(f"{py_file.name}: æœªæ‰¾åˆ°æ¨¡å‹ç±»")
                        result['suggestions'].append(f"åœ¨{py_file.name}ä¸­å®šä¹‰ç»§æ‰¿nn.Moduleçš„æ¨¡å‹ç±»")

            except Exception as e:
                error_msg = f"{py_file.name}: {str(e)}"
                result['issues'].append(error_msg)
                result['suggestions'].append(f"ä¿®å¤{py_file.name}ä¸­çš„å¯¼å…¥æˆ–è¯­æ³•é”™è¯¯")

        return result

    def test_model_training(self, model_name: str) -> Dict[str, Any]:
        """æµ‹è¯•æ¨¡å‹è®­ç»ƒ"""
        result = {
            'data_loading': False,
            'model_initialization': False,
            'forward_pass': False,
            'training_loop': False,
            'issues': [],
            'suggestions': []
        }

        # åŠ è½½ç¤ºä¾‹æ•°æ®
        features, labels = self.load_sample_data()
        if features is None or labels is None:
            result['issues'].append("æ— æ³•åŠ è½½ç¤ºä¾‹æ•°æ®")
            return result

        result['data_loading'] = True

        try:
            model_path = self.models_dir / model_name
            if str(model_path) not in sys.path:
                sys.path.insert(0, str(model_path))

            # å°è¯•å¯¼å…¥ä¸»è¦æ¨¡å—
            main_module = None
            for py_file in model_path.glob('*unified.py'):
                try:
                    module_name = py_file.stem
                    import importlib.util
                    spec = importlib.util.spec_from_file_location(module_name, py_file)
                    if spec and spec.loader:
                        module = importlib.util.module_from_spec(spec)
                        spec.loader.exec_module(module)
                        main_module = module
                        break
                except:
                    continue

            if not main_module:
                result['issues'].append("æ— æ³•å¯¼å…¥æ¨¡å‹æ¨¡å—")
                return result

            # æŸ¥æ‰¾æ¨¡å‹ç±»
            model_class = None
            for attr_name in dir(main_module):
                attr = getattr(main_module, attr_name)
                if hasattr(attr, '__bases__') and hasattr(attr, 'forward'):
                    if 'Model' in attr_name and 'BaseModel' not in attr_name:
                        model_class = attr
                        break

            if not model_class:
                result['issues'].append("æœªæ‰¾åˆ°æ¨¡å‹ç±»")
                return result

            # åˆå§‹åŒ–æ¨¡å‹
            try:
                # ç®€åŒ–æ¨¡å‹åˆå§‹åŒ–ï¼ˆå®é™…å¯èƒ½éœ€è¦æ›´å¤šå‚æ•°ï¼‰
                if 'BayesianCNN' in model_name:
                    model = model_class(input_dim=features.shape[1])
                elif 'XGBoost' in model_name:
                    model = model_class()
                else:
                    model = model_class()

                result['model_initialization'] = True
            except Exception as e:
                result['issues'].append(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
                result['suggestions'].append("æ£€æŸ¥æ¨¡å‹æ„é€ å‡½æ•°å‚æ•°")
                return result

            # æµ‹è¯•å‰å‘ä¼ æ’­
            try:
                # å‡†å¤‡è¾“å…¥æ•°æ®
                if hasattr(model, 'forward'):
                    # è½¬æ¢ä¸ºtensor
                    if isinstance(features, pd.DataFrame):
                        X_sample = torch.tensor(features.iloc[:32].values, dtype=torch.float32)
                    else:
                        X_sample = torch.tensor(features[:32], dtype=torch.float32)

                    with torch.no_grad():
                        output = model(X_sample)
                        result['forward_pass'] = True
                else:
                    result['issues'].append("æ¨¡å‹æ²¡æœ‰forwardæ–¹æ³•")
            except Exception as e:
                result['issues'].append(f"å‰å‘ä¼ æ’­å¤±è´¥: {e}")
                result['suggestions'].append("æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼å’Œæ¨¡å‹forwardæ–¹æ³•")

            # å°è¯•ç®€å•çš„è®­ç»ƒå¾ªç¯
            try:
                if hasattr(model, 'parameters'):
                    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
                    criterion = torch.nn.CrossEntropyLoss()

                    model.train()
                    for _ in range(1):  # åªè®­ç»ƒ1æ­¥
                        optimizer.zero_grad()
                        output = model(X_sample)
                        y_sample = torch.tensor(labels[:32], dtype=torch.long)
                        loss = criterion(output, y_sample)
                        loss.backward()
                        optimizer.step()

                    result['training_loop'] = True
            except Exception as e:
                result['issues'].append(f"è®­ç»ƒå¾ªç¯å¤±è´¥: {e}")

        except Exception as e:
            result['issues'].append(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

        return result

    def generate_debug_report(self, model_name: str) -> str:
        """ç”Ÿæˆè°ƒè¯•æŠ¥å‘Š"""
        print(f"\nğŸ” è°ƒè¯•æ¨¡å‹: {model_name}")
        print("=" * 60)

        report_lines = [f"# {model_name} è°ƒè¯•æŠ¥å‘Š", ""]

        # é…ç½®è¯Šæ–­
        config_result = self.diagnose_model_config(model_name)
        report_lines.append("## ğŸ“‹ é…ç½®è¯Šæ–­")
        report_lines.append(f"- é…ç½®æœ‰æ•ˆ: {'âœ…' if config_result['config_valid'] else 'âŒ'}")
        report_lines.append(f"- åˆ†ç±»æ•°é‡æ­£ç¡®: {'âœ…' if config_result['num_classes_correct'] else 'âŒ'}")
        report_lines.append(f"- è¾“å‡ºç»´åº¦æ­£ç¡®: {'âœ…' if config_result['output_dim_correct'] else 'âŒ'}")
        report_lines.append(f"- æŸå¤±å‡½æ•°æ­£ç¡®: {'âœ…' if config_result['loss_function_correct'] else 'âŒ'}")

        if config_result['issues']:
            report_lines.append("\n**é—®é¢˜:**")
            for issue in config_result['issues']:
                report_lines.append(f"- {issue}")

        if config_result['suggestions']:
            report_lines.append("\n**å»ºè®®:**")
            for suggestion in config_result['suggestions']:
                report_lines.append(f"- {suggestion}")

        # ä»£ç è¯Šæ–­
        code_result = self.diagnose_model_code(model_name)
        report_lines.append("\n## ğŸ’» ä»£ç è¯Šæ–­")
        report_lines.append(f"- ä»£ç å­˜åœ¨: {'âœ…' if code_result['code_exists'] else 'âŒ'}")
        report_lines.append(f"- å¯¼å…¥æˆåŠŸ: {'âœ…' if code_result['imports_work'] else 'âŒ'}")
        report_lines.append(f"- ç±»ç»“æ„æ­£ç¡®: {'âœ…' if code_result['class_structure'] else 'âŒ'}")
        report_lines.append(f"- å‰å‘æ–¹æ³•å­˜åœ¨: {'âœ…' if code_result['forward_method'] else 'âŒ'}")
        report_lines.append(f"- è®­ç»ƒæ–¹æ³•å­˜åœ¨: {'âœ…' if code_result['training_method'] else 'âŒ'}")

        if code_result['issues']:
            report_lines.append("\n**é—®é¢˜:**")
            for issue in code_result['issues']:
                report_lines.append(f"- {issue}")

        if code_result['suggestions']:
            report_lines.append("\n**å»ºè®®:**")
            for suggestion in code_result['suggestions']:
                report_lines.append(f"- {suggestion}")

        # è®­ç»ƒæµ‹è¯•
        train_result = self.test_model_training(model_name)
        report_lines.append("\n## ğŸƒ è®­ç»ƒæµ‹è¯•")
        report_lines.append(f"- æ•°æ®åŠ è½½: {'âœ…' if train_result['data_loading'] else 'âŒ'}")
        report_lines.append(f"- æ¨¡å‹åˆå§‹åŒ–: {'âœ…' if train_result['model_initialization'] else 'âŒ'}")
        report_lines.append(f"- å‰å‘ä¼ æ’­: {'âœ…' if train_result['forward_pass'] else 'âŒ'}")
        report_lines.append(f"- è®­ç»ƒå¾ªç¯: {'âœ…' if train_result['training_loop'] else 'âŒ'}")

        if train_result['issues']:
            report_lines.append("\n**é—®é¢˜:**")
            for issue in train_result['issues']:
                report_lines.append(f"- {issue}")

        if train_result['suggestions']:
            report_lines.append("\n**å»ºè®®:**")
            for suggestion in train_result['suggestions']:
                report_lines.append(f"- {suggestion}")

        return "\n".join(report_lines)

    def debug_all_models(self):
        """è°ƒè¯•æ‰€æœ‰æ¨¡å‹"""
        print("ğŸš€ å¼€å§‹å…¨é¢æ¨¡å‹è°ƒè¯•...")

        for model_name in self.model_names:
            try:
                report = self.generate_debug_report(model_name)
                print(report)

                # ä¿å­˜å•ä¸ªæŠ¥å‘Š
                report_path = self.models_dir / f"{model_name}_debug_report.md"
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report)

                print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

            except Exception as e:
                print(f"âŒ è°ƒè¯•{model_name}æ—¶å‡ºé”™: {e}")
                traceback.print_exc()

        print("\nğŸ‰ è°ƒè¯•å®Œæˆ!")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="é‡åŒ–äº¤æ˜“æ¨¡å‹è°ƒè¯•å·¥å…·")
    parser.add_argument('--model', type=str, help='æŒ‡å®šè°ƒè¯•çš„æ¨¡å‹åç§°')
    parser.add_argument('--all', action='store_true', help='è°ƒè¯•æ‰€æœ‰æ¨¡å‹')

    args = parser.parse_args()

    debugger = ModelDebugger()

    if args.model:
        report = debugger.generate_debug_report(args.model)
        print(report)

        # ä¿å­˜æŠ¥å‘Š
        report_path = debugger.models_dir / f"{args.model}_debug_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    elif args.all:
        debugger.debug_all_models()
    else:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python debug_model.py --model <model_name>    # è°ƒè¯•å•ä¸ªæ¨¡å‹")
        print("  python debug_model.py --all                  # è°ƒè¯•æ‰€æœ‰æ¨¡å‹")
        print("\nå¯ç”¨æ¨¡å‹:")
        for model in debugger.model_names:
            print(f"  - {model}")

if __name__ == "__main__":
    main()
