#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
create_sample_data.py - åˆ›å»ºç¤ºä¾‹æ•°æ®é›†ä¾›æ‰€æœ‰æ¨¡å‹æµ‹è¯•ä½¿ç”¨
"""

import numpy as np
import pandas as pd
from pathlib import Path
import argparse
import yaml
from typing import Dict, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

class SampleDataGenerator:
    """ç¤ºä¾‹æ•°æ®ç”Ÿæˆå™¨"""

    def __init__(self):
        self.random_seed = 42
        np.random.seed(self.random_seed)

    def generate_base_features(self, n_samples: int = 10000) -> pd.DataFrame:
        """ç”ŸæˆåŸºç¡€ç‰¹å¾æ•°æ®"""
        features = {}

        # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        for i in range(20):
            features[f'tech_indicator_{i}'] = np.random.randn(n_samples)

        # ä»·æ ¼ç›¸å…³ç‰¹å¾
        features['close_price'] = 100 * np.exp(np.cumsum(np.random.randn(n_samples) * 0.01))
        features['open_price'] = features['close_price'] * (1 + np.random.randn(n_samples) * 0.02)
        features['high_price'] = np.maximum(features['open_price'], features['close_price']) * (1 + np.abs(np.random.randn(n_samples)) * 0.03)
        features['low_price'] = np.minimum(features['open_price'], features['close_price']) * (1 - np.abs(np.random.randn(n_samples)) * 0.03)
        features['volume'] = np.abs(np.random.randn(n_samples)) * 1000000 + 500000

        # æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
        close_series = pd.Series(features['close_price'])
        features['returns'] = np.log(close_series / close_series.shift(1)).fillna(0)
        features['ma5'] = close_series.rolling(5).mean().fillna(close_series)
        features['ma20'] = close_series.rolling(20).mean().fillna(close_series)
        features['ma60'] = close_series.rolling(60).mean().fillna(close_series)
        features['rsi'] = self._calculate_rsi(close_series)
        features['macd'], features['macd_signal'] = self._calculate_macd(close_series)
        features['bb_upper'], features['bb_middle'], features['bb_lower'] = self._calculate_bollinger_bands(close_series)

        # åŸºæœ¬é¢ç‰¹å¾
        for i in range(15):
            features[f'fundamental_{i}'] = np.random.randn(n_samples)

        # ä¼°å€¼æŒ‡æ ‡
        features['pe_ratio'] = np.abs(np.random.randn(n_samples)) * 50 + 10
        features['pb_ratio'] = np.abs(np.random.randn(n_samples)) * 5 + 0.5
        features['roe'] = np.random.randn(n_samples) * 0.1 + 0.15
        features['net_profit_growth'] = np.random.randn(n_samples) * 0.2

        # å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
        features['bid_ask_spread'] = np.abs(np.random.randn(n_samples)) * 0.001 + 0.0005
        features['order_book_depth'] = np.abs(np.random.randn(n_samples)) * 1000 + 500
        features['trade_frequency'] = np.abs(np.random.randn(n_samples)) * 100 + 50
        features['market_impact'] = np.random.randn(n_samples) * 0.01

        return pd.DataFrame(features)

    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.fillna(50)

    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series]:
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd.fillna(0), macd_signal.fillna(0)

    def _calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """è®¡ç®—å¸ƒæ—å¸¦"""
        middle = prices.rolling(window=period).mean()
        std = prices.rolling(window=period).std()
        upper = middle + (std * std_dev)
        lower = middle - (std * std_dev)
        return upper.fillna(prices), middle.fillna(prices), lower.fillna(prices)

    def generate_labels(self, features: pd.DataFrame) -> np.ndarray:
        """ç”Ÿæˆä¸‰åˆ†ç±»æ ‡ç­¾ (-1, 0, 1)"""
        n_samples = len(features)

        # åŸºäºå¤šä¸ªå› å­ç”Ÿæˆæ›´çœŸå®çš„æ ‡ç­¾
        returns = features['returns'].values

        # æ·»åŠ ä¸€äº›æŠ€æœ¯æŒ‡æ ‡çš„å½±å“
        ma_signal = (features['close_price'] > features['ma20']).astype(int) - 0.5
        rsi_signal = ((features['rsi'] > 70).astype(int) - (features['rsi'] < 30).astype(int))

        # ç»¼åˆä¿¡å·
        combined_signal = returns * 0.5 + ma_signal * 0.3 + rsi_signal * 0.2

        # æ·»åŠ å™ªå£°
        noise = np.random.randn(n_samples) * 0.1
        final_signal = combined_signal + noise

        # ç”Ÿæˆæ ‡ç­¾
        labels = np.zeros(n_samples, dtype=int)
        labels[final_signal > 0.05] = 1   # ä¸Šæ¶¨
        labels[final_signal < -0.05] = -1  # ä¸‹è·Œ
        # ä¸­é—´ä¿æŒä¸º0ï¼ˆéœ‡è¡ï¼‰

        return labels

    def generate_multifrequency_data(self, base_features: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """ç”Ÿæˆå¤šé¢‘ç‡æ•°æ®ï¼ˆç”¨äºæ··åˆé¢‘ç‡æ¨¡å‹ï¼‰"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»åŸå§‹é«˜é¢‘æ•°æ®èšåˆ

        # æ—¥é¢‘æ•°æ®å°±æ˜¯åŸºç¡€æ•°æ®
        daily_data = base_features.copy()

        # æ¨¡æ‹Ÿå‘¨é¢‘æ•°æ®ï¼ˆæŒ‰å‘¨èšåˆï¼‰
        if 'date' in base_features.columns:
            base_features = base_features.set_index('date')
            weekly_data = base_features.resample('W').agg({
                col: 'last' if col in ['close_price', 'volume'] else 'mean'
                for col in base_features.columns
                if col != 'instrument'
            }).reset_index()
        else:
            weekly_data = base_features.copy()  # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œä½¿ç”¨åŸæ•°æ®

        # æ¨¡æ‹Ÿæ—¥å†…æ•°æ®ï¼ˆç®€å•å¤åˆ¶æ—¥é¢‘æ•°æ®ï¼Œæ·»åŠ æ—¶é—´ä¿¡æ¯ï¼‰
        intraday_data = base_features.copy()
        if 'date' in intraday_data.columns:
            intraday_data = intraday_data.reset_index(drop=True)
            # ä¸ºæ¯è¡Œæ·»åŠ éšæœºæ—¶é—´æˆ³ï¼ˆæ¨¡æ‹Ÿæ—¥å†…æ•°æ®ï¼‰
            base_times = pd.date_range('09:30:00', '15:00:00', freq='1H').time
            intraday_data['time'] = np.random.choice(base_times, len(intraday_data))
            intraday_data['datetime'] = intraday_data.apply(
                lambda row: pd.Timestamp.combine(row['date'].date(), row['time']), axis=1
            )

        return {
            'weekly': weekly_data,
            'daily': daily_data,
            'intraday': intraday_data
        }

    def create_complete_dataset(self, n_samples: int = 10000) -> Dict[str, Any]:
        """åˆ›å»ºå®Œæ•´çš„æ•°æ®é›†"""
        print(f"ğŸ”§ ç”Ÿæˆ {n_samples} æ¡ç¤ºä¾‹æ•°æ®...")

        # ç”ŸæˆåŸºç¡€ç‰¹å¾
        features = self.generate_base_features(n_samples)

        # æ·»åŠ æ—¶é—´å’Œè‚¡ç¥¨ä¿¡æ¯
        features['date'] = pd.date_range('2015-01-01', periods=n_samples, freq='D')
        features['instrument'] = np.random.choice(['000001.SZ', '000002.SZ', '600000.SH'], n_samples)
        features['weight'] = np.ones(n_samples)  # æ ·æœ¬æƒé‡

        # ç”Ÿæˆæ ‡ç­¾
        labels = self.generate_labels(features)
        features['label'] = labels

        # ç”Ÿæˆå¤šé¢‘ç‡æ•°æ®
        multifreq_data = self.generate_multifrequency_data(features[['date'] + [col for col in features.columns if col not in ['date', 'instrument', 'weight']]])

        dataset = {
            'features': features,
            'labels': labels,
            'multifrequency': multifreq_data
        }

        print("âœ… æ•°æ®ç”Ÿæˆå®Œæˆ")
        print(f"   - æ ·æœ¬æ•°é‡: {n_samples}")
        print(f"   - ç‰¹å¾æ•°é‡: {len(features.columns)}")
        print(f"   - æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels + 1)} (-1, 0, 1)")

        return dataset

    def save_dataset(self, dataset: Dict[str, Any], output_dir: str = "sample_data"):
        """ä¿å­˜æ•°æ®é›†"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # ä¿å­˜ä¸»æ•°æ®é›†
        dataset['features'].to_csv(output_path / "features.csv", index=False)
        np.save(output_path / "labels.npy", dataset['labels'])

        # ä¿å­˜å¤šé¢‘ç‡æ•°æ®
        for freq_name, freq_data in dataset['multifrequency'].items():
            freq_data.to_csv(output_path / f"{freq_name}_features.csv", index=False)

        # ä¿å­˜æ•°æ®ä¿¡æ¯
        info = {
            'n_samples': len(dataset['features']),
            'n_features': len(dataset['features'].columns),
            'label_distribution': np.bincount(dataset['labels'] + 1).tolist(),
            'date_range': [
                dataset['features']['date'].min().strftime('%Y-%m-%d'),
                dataset['features']['date'].max().strftime('%Y-%m-%d')
            ],
            'instruments': dataset['features']['instrument'].unique().tolist()
        }

        with open(output_path / "dataset_info.yaml", 'w', encoding='utf-8') as f:
            yaml.dump(info, f, default_flow_style=False)

        print(f"ğŸ’¾ æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_path}")

    def create_model_specific_data(self, model_name: str) -> Dict[str, Any]:
        """ä¸ºç‰¹å®šæ¨¡å‹åˆ›å»ºå®šåˆ¶æ•°æ®"""
        base_dataset = self.create_complete_dataset()

        if 'æ··åˆé¢‘ç‡' in model_name:
            # ä¸ºæ··åˆé¢‘ç‡æ¨¡å‹å‡†å¤‡ç‰¹å®šæ ¼å¼
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç‰¹å®šé¢„å¤„ç†
            pass
        elif 'BayesianCNN' in model_name:
            # ä¸ºBayesianCNNå‡†å¤‡æ•°æ®
            pass
        elif 'XGBoost' in model_name:
            # ä¸ºXGBoostå‡†å¤‡è¡¨æ ¼æ•°æ®
            pass

        return base_dataset

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åˆ›å»ºé‡åŒ–äº¤æ˜“æ¨¡å‹ç¤ºä¾‹æ•°æ®")
    parser.add_argument('--n_samples', type=int, default=10000, help='æ ·æœ¬æ•°é‡')
    parser.add_argument('--output_dir', type=str, default='sample_data', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model', type=str, default=None, help='ç‰¹å®šæ¨¡å‹åç§°')

    args = parser.parse_args()

    generator = SampleDataGenerator()

    if args.model:
        print(f"ğŸ¯ ä¸ºæ¨¡å‹ {args.model} åˆ›å»ºå®šåˆ¶æ•°æ®")
        dataset = generator.create_model_specific_data(args.model)
    else:
        print("ğŸ“Š åˆ›å»ºé€šç”¨ç¤ºä¾‹æ•°æ®")
        dataset = generator.create_complete_dataset(args.n_samples)

    generator.save_dataset(dataset, args.output_dir)

    print("ğŸ‰ æ•°æ®åˆ›å»ºå®Œæˆï¼")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“„ åŒ…å«æ–‡ä»¶: features.csv, labels.npy, å¤šé¢‘ç‡æ•°æ®ç­‰")

if __name__ == "__main__":
    main()
