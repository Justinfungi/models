#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
training.py - ConvM_Lstm æ¨¡å‹è®­ç»ƒè„šæœ¬
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
import yaml
import os
import sys
import argparse
import numpy as np
import pandas as pd
from typing import Dict, Any, Optional, Tuple, List
import logging
from datetime import datetime
import json
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
# å‘ä¸ŠæŸ¥æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½• (b_model_reproduction_agent)
project_root = current_dir
while not os.path.exists(os.path.join(project_root, 'data')) and project_root != '/':
    project_root = os.path.dirname(project_root)
sys.path.append(project_root)

try:
    from model import ConvM_Lstm
except ImportError as e:
    print(f"æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ model.py æ–‡ä»¶å­˜åœ¨ä¸”åŒ…å« ConvM_Lstm ç±»")
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å ä½ç¬¦æ¨¡å‹
    class ConvM_Lstm(nn.Module):
        def __init__(self, config):
            super().__init__()
            self.fc = nn.Linear(20, 2)  # ç®€å•çš„çº¿æ€§å±‚
        
        def forward(self, x):
            # x shape: (batch_size, seq_len, features)
            x = x.mean(dim=1)  # å¹³å‡æ± åŒ–
            return self.fc(x)


class ConvM_LstmTrainer:
    """
    ConvM_Lstmæ¨¡å‹è®­ç»ƒå™¨
    
    è´Ÿè´£æ¨¡å‹çš„è®­ç»ƒã€éªŒè¯å’Œä¿å­˜
    """
    
    def __init__(self, config_path: str, quick_test: bool = False):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            quick_test: æ˜¯å¦ä¸ºå¿«é€Ÿæµ‹è¯•æ¨¡å¼
        """
        self.quick_test = quick_test
        self.config = self._load_config(config_path)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = None
        self.optimizer = None
        self.criterion = None
        self.scaler = StandardScaler()
        
        # è®­ç»ƒçŠ¶æ€
        self.best_val_loss = float('inf')
        self.best_val_acc = 0.0
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []
        
        self.logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {self.device}")
        if self.quick_test:
            self.logger.info("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼å·²å¯ç”¨")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
        """
        try:
            if not os.path.exists(config_path):
                print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                print("ä½¿ç”¨é»˜è®¤é…ç½®...")
                return self._get_default_config()
                
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            print("ä½¿ç”¨é»˜è®¤é…ç½®...")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'architecture': {
                'seq_len': 60,
                'num_features': 20
            },
            'data': {
                'target_column': 'label',
                'split': {
                    'train_ratio': 0.7,
                    'val_ratio': 0.15,
                    'random_seed': 42
                }
            },
            'training': {
                'batch_size': 32,
                'learning_rate': 0.001,
                'weight_decay': 1e-5,
                'epochs': 100
            }
        }
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_dir = os.path.join(os.path.dirname(__file__), 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(log_dir, f'training_{timestamp}.log')
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _load_data(self) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """
        åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        
        Returns:
            è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ•°æ®åŠ è½½å™¨
        """
        try:
            # æ•°æ®è·¯å¾„
            data_config = self.config['data']
            
            # ä¿®å¤æ•°æ®è·¯å¾„ï¼šç›´æ¥ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„dataæ–‡ä»¶å¤¹
            data_path = os.path.join(project_root, "data")
            
            # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
            data_files = []
            for root, dirs, files in os.walk(data_path):
                for file in files:
                    if file.endswith('.parquet') or file.endswith('.pq'):
                        data_files.append(os.path.join(root, file))
            
            if not data_files:
                self.logger.warning(f"åœ¨ {data_path} ä¸­æœªæ‰¾åˆ° .parquet æˆ– .pq æ–‡ä»¶ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")
                df = self._generate_dummy_data()
            else:
                # åŠ è½½ç¬¬ä¸€ä¸ªæ•°æ®æ–‡ä»¶
                df = pd.read_parquet(data_files[0])
                self.logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå½¢çŠ¶: {df.shape}")
            
            # æå–ç‰¹å¾å’Œæ ‡ç­¾
            feature_cols = [col for col in df.columns if '@' in col]
            if not feature_cols:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°@ç¬¦å·çš„ç‰¹å¾åˆ—ï¼Œä½¿ç”¨é™¤æœ€åä¸€åˆ—å¤–çš„æ‰€æœ‰æ•°å€¼åˆ—
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                feature_cols = numeric_cols[:-1] if len(numeric_cols) > 1 else numeric_cols
                self.logger.warning(f"æœªæ‰¾åˆ°åŒ…å«'@'çš„ç‰¹å¾åˆ—ï¼Œä½¿ç”¨æ•°å€¼åˆ—: {len(feature_cols)} ä¸ªç‰¹å¾")
            
            target_col = data_config.get('target_column', 'label')
            
            if target_col not in df.columns:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‡å®šçš„ç›®æ ‡åˆ—ï¼Œä½¿ç”¨æœ€åä¸€åˆ—
                target_col = df.columns[-1]
                self.logger.warning(f"æœªæ‰¾åˆ°ç›®æ ‡åˆ— {data_config.get('target_column')}ï¼Œä½¿ç”¨ {target_col}")
            
            X = df[feature_cols].values
            y = df[target_col].values
            
            # ç¡®ä¿yæ˜¯æ•°å€¼ç±»å‹
            if y.dtype == 'object' or y.dtype.kind in ['U', 'S']:  # å­—ç¬¦ä¸²ç±»å‹
                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                try:
                    y = pd.to_numeric(y, errors='coerce')
                    # å¤„ç†NaNå€¼
                    if np.isnan(y).any():
                        self.logger.warning("ç›®æ ‡åˆ—åŒ…å«éæ•°å€¼æ•°æ®ï¼Œå°†ä½¿ç”¨äºŒåˆ†ç±»æ ‡ç­¾")
                        y = (y > np.nanmedian(y)).astype(int)
                except:
                    # å¦‚æœæ— æ³•è½¬æ¢ï¼Œåˆ›å»ºåˆ†ç±»æ ‡ç­¾
                    unique_vals = np.unique(y)
                    y = np.array([np.where(unique_vals == val)[0][0] for val in y])
                    self.logger.warning(f"ç›®æ ‡åˆ—è½¬æ¢ä¸ºåˆ†ç±»æ ‡ç­¾ï¼Œç±»åˆ«æ•°: {len(unique_vals)}")
            
            # ç¡®ä¿yæ˜¯æ•´æ•°ç±»å‹ç”¨äºåˆ†ç±»
            if y.dtype.kind == 'f':  # æµ®ç‚¹æ•°
                y = y.astype(int)
            
            # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, num_classes-1]
            num_classes = self.config['architecture']['fc']['num_classes']
            unique_labels = np.unique(y)
            self.logger.info(f"åŸå§‹æ ‡ç­¾èŒƒå›´: {unique_labels}")
            
            if len(unique_labels) > num_classes:
                self.logger.warning(f"æ ‡ç­¾ç±»åˆ«æ•°({len(unique_labels)})è¶…è¿‡é…ç½®çš„ç±»åˆ«æ•°({num_classes})")
                # é‡æ–°æ˜ å°„æ ‡ç­¾åˆ° [0, num_classes-1]
                y = np.digitize(y, np.percentile(y, np.linspace(0, 100, num_classes+1)[1:-1])) - 1
                y = np.clip(y, 0, num_classes-1)
            elif unique_labels.min() < 0 or unique_labels.max() >= num_classes:
                # é‡æ–°æ˜ å°„æ ‡ç­¾åˆ° [0, num_classes-1]
                y_min, y_max = y.min(), y.max()
                y = ((y - y_min) / (y_max - y_min) * (num_classes - 1)).astype(int)
                y = np.clip(y, 0, num_classes-1)
            
            self.logger.info(f"å¤„ç†åæ ‡ç­¾èŒƒå›´: {np.unique(y)}")
            
            # å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å°‘é‡æ•°æ®
            if self.quick_test:
                sample_size = min(100, len(X))
                indices = np.random.choice(len(X), sample_size, replace=False)
                X = X[indices]
                y = y[indices]
                self.logger.info(f"å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨ {sample_size} ä¸ªæ ·æœ¬")
            
            # æ•°æ®æ ‡å‡†åŒ–
            X = self.scaler.fit_transform(X)
            
            # è½¬æ¢ä¸ºæ—¶é—´åºåˆ—æ ¼å¼
            seq_len = self.config['architecture']['seq_len']
            num_features = self.config['architecture']['num_features']
            
            # é‡å¡‘æ•°æ®ä¸ºæ—¶é—´åºåˆ—æ ¼å¼
            if X.shape[1] >= seq_len * num_features:
                X_reshaped = X[:, :seq_len * num_features].reshape(-1, seq_len, num_features)
            else:
                # å¦‚æœç‰¹å¾æ•°ä¸å¤Ÿï¼Œè¿›è¡Œå¡«å……æˆ–æˆªæ–­
                needed_features = seq_len * num_features
                if X.shape[1] < needed_features:
                    # å¡«å……
                    padding = np.zeros((X.shape[0], needed_features - X.shape[1]))
                    X = np.concatenate([X, padding], axis=1)
                X_reshaped = X[:, :needed_features].reshape(-1, seq_len, num_features)
            
            # è½¬æ¢ä¸ºå¼ é‡
            X_tensor = torch.FloatTensor(X_reshaped)
            y_tensor = torch.LongTensor(y)
            
            # åˆ›å»ºæ•°æ®é›†
            dataset = TensorDataset(X_tensor, y_tensor)
            
            # æ•°æ®åˆ†å‰² - ä¿®å¤é…ç½®è·¯å¾„
            data_split_config = self.config['data'].get('split', self.config['data'])
            train_ratio = data_split_config.get('train_ratio', 0.7)
            val_ratio = data_split_config.get('val_ratio', 0.15)
            random_seed = data_split_config.get('random_seed', 42)
            
            train_size = int(train_ratio * len(dataset))
            val_size = int(val_ratio * len(dataset))
            test_size = len(dataset) - train_size - val_size
            
            train_dataset, val_dataset, test_dataset = random_split(
                dataset, [train_size, val_size, test_size],
                generator=torch.Generator().manual_seed(random_seed)
            )
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¿®å¤é…ç½®è·¯å¾„
            batch_size = self.config.get('training', {}).get('batch_size', 32)
            if self.quick_test:
                batch_size = min(16, batch_size)  # å¿«é€Ÿæµ‹è¯•ä½¿ç”¨æ›´å°çš„æ‰¹æ¬¡
            
            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
            
            self.logger.info(f"æ•°æ®åˆ†å‰²å®Œæˆ - è®­ç»ƒ: {len(train_dataset)}, éªŒè¯: {len(val_dataset)}, æµ‹è¯•: {len(test_dataset)}")
            
            return train_loader, val_loader, test_loader
            
        except Exception as e:
            self.logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _generate_dummy_data(self) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•"""
        np.random.seed(42)
        n_samples = 1000 if not self.quick_test else 100
        n_features = 50
        
        # ç”Ÿæˆç‰¹å¾æ•°æ®
        data = {}
        for i in range(n_features):
            data[f'feature_{i}@time'] = np.random.randn(n_samples)
        
        # ç”Ÿæˆæ ‡ç­¾
        data['label'] = np.random.randint(0, 2, n_samples)
        
        df = pd.DataFrame(data)
        self.logger.info(f"ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼Œå½¢çŠ¶: {df.shape}")
        return df
    
    def _initialize_model(self) -> None:
        """åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°"""
        try:
            # åˆ›å»ºæ¨¡å‹
            self.model = ConvM_Lstm(self.config).to(self.device)
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            training_config = self.config.get('training', {})
            lr = float(training_config.get('learning_rate', 0.001))
            weight_decay = float(training_config.get('weight_decay', 1e-5))
            
            self.optimizer = optim.Adam(
                self.model.parameters(),
                lr=lr,
                weight_decay=weight_decay
            )
            
            # åˆ›å»ºæŸå¤±å‡½æ•°
            self.criterion = nn.CrossEntropyLoss()
            
            # å­¦ä¹ ç‡è°ƒåº¦å™¨
            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer, mode='min', factor=0.5, patience=5, verbose=True
            )
            
            self.logger.info("æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            self.logger.info(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters())}")
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def train_epoch(self, train_loader: DataLoader) -> Tuple[float, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            
        Returns:
            å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        """
        self.model.train()
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device), target.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            pred = output.argmax(dim=1)
            total_correct += pred.eq(target).sum().item()
            total_samples += target.size(0)
            
            if batch_idx % 10 == 0:
                self.logger.debug(f'æ‰¹æ¬¡ {batch_idx}/{len(train_loader)}, æŸå¤±: {loss.item():.6f}')
        
        avg_loss = total_loss / len(train_loader)
        accuracy = total_correct / total_samples
        
        return avg_loss, accuracy
    
    def validate(self, val_loader: DataLoader) -> Tuple[float, float, Dict[str, float]]:
        """
        éªŒè¯æ¨¡å‹æ€§èƒ½
        
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            
        Returns:
            å¹³å‡æŸå¤±ã€å‡†ç¡®ç‡å’Œè¯¦ç»†æŒ‡æ ‡
        """
        self.model.eval()
        total_loss = 0.0
        all_preds = []
        all_targets = []
        all_probs = []
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                
                output = self.model(data)
                loss = self.criterion(output, target)
                
                total_loss += loss.item()
                
                # æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
                pred = output.argmax(dim=1)
                prob = torch.softmax(output, dim=1)
                
                all_preds.extend(pred.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
                all_probs.extend(prob.cpu().numpy())
        
        avg_loss = total_loss / len(val_loader)
        
        # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
        all_preds = np.array(all_preds)
        all_targets = np.array(all_targets)
        all_probs = np.array(all_probs)
        
        accuracy = accuracy_score(all_targets, all_preds)
        precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0)
        recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0)
        f1 = f1_score(all_targets, all_preds, average='weighted', zero_division=0)
        
        # ROC AUC (ä»…å¯¹äºŒåˆ†ç±»æœ‰æ•ˆ)
        try:
            if len(np.unique(all_targets)) == 2:
                auc = roc_auc_score(all_targets, all_probs[:, 1])
            else:
                auc = roc_auc_score(all_targets, all_probs, multi_class='ovr', average='weighted')
        except:
            auc = 0.0
        
        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc': auc
        }
        
        return avg_loss, accuracy, metrics
    
    def save_model(self, epoch: int, metrics: Dict[str, float], is_best: bool = False) -> None:
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            epoch: å½“å‰epoch
            metrics: éªŒè¯æŒ‡æ ‡
            is_best: æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        """
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            save_dir = os.path.join(os.path.dirname(__file__), 'checkpoints')
            os.makedirs(save_dir, exist_ok=True)
            
            # ä¿å­˜çŠ¶æ€
            state = {
                'epoch': epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'config': self.config,
                'metrics': metrics,
                'train_losses': self.train_losses,
                'val_losses': self.val_losses,
                'train_accs': self.train_accs,
                'val_accs': self.val_accs,
                'scaler': self.scaler
            }
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')
            torch.save(state, checkpoint_path)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if is_best:
                best_path = os.path.join(save_dir, 'best_model.pth')
                torch.save(state, best_path)
                self.logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {best_path}")
            
            self.logger.info(f"æ¨¡å‹æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
    
    def train(self) -> None:
        """æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        try:
            self.logger.info("å¼€å§‹è®­ç»ƒæµç¨‹...")
            
            # åŠ è½½æ•°æ®
            train_loader, val_loader, test_loader = self._load_data()
            
            # åˆå§‹åŒ–æ¨¡å‹
            self._initialize_model()
            
            # è®­ç»ƒå‚æ•°
            training_config = self.config.get('training', {})
            num_epochs = training_config.get('epochs', 100)
            
            if self.quick_test:
                num_epochs = min(2, num_epochs)  # å¿«é€Ÿæµ‹è¯•åªè®­ç»ƒ2ä¸ªepoch
                self.logger.info(f"å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šè®­ç»ƒ {num_epochs} ä¸ªepoch")
            
            # è®­ç»ƒå¾ªç¯
            for epoch in range(num_epochs):
                self.logger.info(f"Epoch {epoch+1}/{num_epochs}")
                
                # è®­ç»ƒ
                train_loss, train_acc = self.train_epoch(train_loader)
                self.train_losses.append(train_loss)
                self.train_accs.append(train_acc)
                
                # éªŒè¯
                val_loss, val_acc, val_metrics = self.validate(val_loader)
                self.val_losses.append(val_loss)
                self.val_accs.append(val_acc)
                
                # å­¦ä¹ ç‡è°ƒåº¦
                self.scheduler.step(val_loss)
                
                # è®°å½•æ—¥å¿—
                self.logger.info(
                    f"è®­ç»ƒæŸå¤±: {train_loss:.6f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}, "
                    f"éªŒè¯æŸå¤±: {val_loss:.6f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}"
                )
                self.logger.info(f"éªŒè¯æŒ‡æ ‡: {val_metrics}")
                
                # ä¿å­˜æ¨¡å‹
                is_best = val_acc > self.best_val_acc
                if is_best:
                    self.best_val_acc = val_acc
                    self.best_val_loss = val_loss
                
                if (epoch + 1) % 10 == 0 or is_best or self.quick_test:
                    self.save_model(epoch + 1, val_metrics, is_best)
                
                # å¿«é€Ÿæµ‹è¯•æ¨¡å¼æå‰ç»“æŸ
                if self.quick_test and epoch >= 0:  # è‡³å°‘è®­ç»ƒ1ä¸ªepoch
                    self.logger.info("å¿«é€Ÿæµ‹è¯•å®Œæˆï¼Œæå‰ç»“æŸè®­ç»ƒ")
                    break
            
            # æœ€ç»ˆæµ‹è¯•
            if not self.quick_test:
                test_loss, test_acc, test_metrics = self.validate(test_loader)
                self.logger.info(f"æœ€ç»ˆæµ‹è¯•ç»“æœ - æŸå¤±: {test_loss:.6f}, å‡†ç¡®ç‡: {test_acc:.4f}")
                self.logger.info(f"æµ‹è¯•æŒ‡æ ‡: {test_metrics}")
            
            self.logger.info("è®­ç»ƒå®Œæˆï¼")
            
        except Exception as e:
            self.logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            raise
    
    def quick_validation(self) -> None:
        """å¿«é€ŸéªŒè¯æ¨¡å¼ï¼šä½¿ç”¨æœ€å°é¢„ç®—éªŒè¯ä»£ç æ­£ç¡®æ€§"""
        self.logger.info("ğŸš€ å¼€å§‹ training.py å¿«é€ŸéªŒè¯...")
        
        try:
            # è®¾ç½®å¿«é€Ÿæµ‹è¯•æ¨¡å¼
            self.quick_test = True
            
            # æ‰§è¡Œè®­ç»ƒ
            self.train()
            
            self.logger.info("âœ… å¿«é€ŸéªŒè¯æˆåŠŸå®Œæˆï¼")
            
        except Exception as e:
            self.logger.error(f"âŒ å¿«é€ŸéªŒè¯å¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ConvM_Lstm æ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--config', type=str, default='config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quick-test', action='store_true',
                       help='å¿«é€ŸéªŒè¯æ¨¡å¼ï¼šä½¿ç”¨æœ€å°é¢„ç®—éªŒè¯è®­ç»ƒè„šæœ¬æ­£ç¡®æ€§')
    
    args = parser.parse_args()
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = os.path.join(os.path.dirname(__file__), args.config)
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ConvM_LstmTrainer(config_path, quick_test=args.quick_test)
        
        if args.quick_test:
            # æ‰§è¡Œå¿«é€ŸéªŒè¯
            trainer.quick_validation()
        else:
            # æ‰§è¡Œæ­£å¸¸è®­ç»ƒ
            trainer.train()
            
    except Exception as e:
        print(f"è®­ç»ƒå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()